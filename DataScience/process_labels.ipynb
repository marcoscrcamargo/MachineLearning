{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import unidecode\n",
    "from pyjarowinkler import distance as jarowinkler\n",
    "import distance\n",
    "import re\n",
    "import arff\n",
    "import time\n",
    "\n",
    "def norm(string):\n",
    "    \"\"\"Normalizes pt-br string\n",
    "\n",
    "    Arguments:\n",
    "        string {str} -- a portuguese type string (ex: não, é muito pouco...)\n",
    "\n",
    "    Returns:\n",
    "        str -- a normalized string (ex: nao, e muito pouco)\n",
    "    \"\"\"\n",
    "    if(isinstance(string, list)):\n",
    "        string = \" \".join(string)\n",
    "\n",
    "    s = unidecode.unidecode(string)\n",
    "    s = s.lower().strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def compare_strings(A, B):\n",
    "    a = norm(A)\n",
    "    b = norm(B)\n",
    "    if(a == b):\n",
    "        return 1\n",
    "\n",
    "    try:\n",
    "        jaro_score = (jarowinkler.get_jaro_distance(a, b, winkler=True, scaling=0.1))\n",
    "    except:\n",
    "        jaro_score = 0\n",
    "        \n",
    "    return jaro_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text, models, nfeatures=None):\n",
    "    # Obtendo indices ordenados do vetor de modelos\n",
    "    idx = np.argsort(list(map(lambda x: len(x), models)))[::-1]\n",
    "\n",
    "    # Organizando features\n",
    "    max_features = 15\n",
    "    features = []\n",
    "\n",
    "    for i in range(max_features):\n",
    "        features.append([])\n",
    "    if(nfeatures == None):\n",
    "        nfeatures = max_features\n",
    "    \n",
    "    # Pré-processando dados\n",
    "    ntext = norm(text)\n",
    "    splited_text = [t.strip() for t in ntext.split(' ') if t.strip() != '']\n",
    "    code = re.compile(r'([0-9-./|a-z-./]*(?:[a-z]-?[0-9]|[0-9]-?[a-z]|[a-z]-[a-z]|[0-9]-?[0-9])[0-9-./|a-z-./]*)')\n",
    "    threshold = 0.8\n",
    "    textgb = re.findall(r'[0-9]+gb', ntext)\n",
    "    ntext_codes = code.findall(ntext)\n",
    "\n",
    "    # Extraindo as features para cada modelo\n",
    "    for model in models:\n",
    "        nmodel= norm(model)\n",
    "        # split do modelo em tokens\n",
    "        splited_model = [m.strip() for m in nmodel.split(' ') if m.strip() != '']\n",
    "\n",
    "        # Número absoluto de tokens em comum (int)\n",
    "        count = 0\n",
    "        for token in splited_text:\n",
    "            for m in splited_model:\n",
    "                if (token == m):\n",
    "                    count += 1\n",
    "        features[0].append(count)\n",
    "\n",
    "        # Número relativo de tokens em comum (double) relativo ao modelo da referencia\n",
    "        features[1].append(count/len(splited_model))\n",
    "\n",
    "        # As palavras da referência ocorrem no título na mesma ordem (binário)\n",
    "        ordered = False\n",
    "        m = 0\n",
    "        for token in splited_text:\n",
    "            if m >= len(splited_model):\n",
    "                ordered = True\n",
    "                break\n",
    "            if (token == splited_model[m]):\n",
    "                m += 1\n",
    "        features[2].append(ordered)\n",
    "\n",
    "        # As palavras da referência ocorrem no título na mesma ordem com jarowinkler > 0.8 (binário)\n",
    "        ordered = False\n",
    "        m = 0\n",
    "        for token in splited_text:\n",
    "            if m >= len(splited_model):\n",
    "                ordered = True\n",
    "                break\n",
    "            if (compare_strings(token, splited_model[m]) > threshold):\n",
    "                m += 1\n",
    "        features[3].append(ordered)\n",
    "\n",
    "        # Palavras em código\n",
    "        count = 0\n",
    "        count_jaro = 0\n",
    "        for token in ntext_codes:\n",
    "            for m in splited_model:\n",
    "                if(code.match(m)):\n",
    "                    if (token == m):\n",
    "                        count += 1\n",
    "                    if (compare_strings(token,m) > threshold):\n",
    "                        count_jaro += 1\n",
    "\n",
    "        # Número de palavras de código em comum (int)                        \n",
    "        features[4].append(count)\n",
    "        if(count == 0):\n",
    "            count_total = 1\n",
    "        # Número de palavras de código em comum relativo\n",
    "        features[5].append(count/len(splited_model))\n",
    "        # Número de palavras de código em comum com jaro\n",
    "        features[6].append(count_jaro)\n",
    "        # Número de palavras de código em comum com jaro relativo\n",
    "        features[7].append(count_jaro/len(splited_model))\n",
    "        \n",
    "        # Utilizar janela deslisante com jaro e edit distance\n",
    "        window = len(splited_text) - len(splited_model) + 1\n",
    "        best_jaro = compare_strings(ntext, nmodel)\n",
    "        best_edit = distance.levenshtein(ntext, nmodel)\n",
    "        for d in range(window):\n",
    "            cmptext = ' '.join(splited_text[d:d+len(splited_model)])\n",
    "            cmp_jaro = compare_strings(cmptext, nmodel)\n",
    "            if(cmp_jaro > best_jaro):\n",
    "                best_jaro = cmp_jaro\n",
    "            \n",
    "            cmp_edit = distance.levenshtein(cmptext, nmodel)\n",
    "            if(cmp_edit < best_edit):\n",
    "                best_edit = cmp_edit\n",
    "        \n",
    "        \n",
    "        features[8].append(best_jaro)\n",
    "        features[9].append(1 - (best_edit/ max(len(ntext), len(nmodel))) )\n",
    "        \n",
    "        # Ordered contains feature\n",
    "        features[10].append(False)\n",
    "\n",
    "        # gb feature\n",
    "        count = 0\n",
    "        if('gb' in ntext and 'gb' in nmodel):\n",
    "            modelgb = re.findall(r'[0-9]+gb', nmodel)\n",
    "            for mgb in modelgb:\n",
    "                if (mgb in textgb):\n",
    "                        count += 1\n",
    "        features[11].append(count)\n",
    "\n",
    "        # dual feature\n",
    "        if('dual' in ntext and ('dual' in nmodel or 'ds' in nmodel)):\n",
    "            features[12].append(True)\n",
    "        else:\n",
    "            features[12].append(False)\n",
    "\n",
    "        # plus or max feature\n",
    "        if(('plus' in ntext and 'plus' in nmodel) or ('max' in ntext and 'max' in nmodel)\n",
    "          or ('maxx' in ntext and 'maxx' in nmodel)):\n",
    "            features[13].append(True)\n",
    "        else:\n",
    "            features[13].append(False)\n",
    "\n",
    "    # ordered contains feature        \n",
    "    for i in range(len(models)):\n",
    "        nmodel = norm(models[idx[i]])\n",
    "        valid = nmodel in ntext\n",
    "        if(valid):\n",
    "            features[10][idx[i]] = valid\n",
    "            break\n",
    "\n",
    "    # voting feature\n",
    "    max_values = [np.max(f) for f in features[0:max_features-2]]\n",
    "    for i in range(len(models)):\n",
    "        row = [f[i] for f in features[0:max_features-2]]\n",
    "        features[14].append(np.sum([r == m for r, m in zip(row, max_values) if m]))\n",
    "            \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3237, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('rotuled/0.tsv', sep='\\t', index_col=False)\n",
    "for i in range(1, 5):\n",
    "    d = pd.read_csv('rotuled/' + str(i) + '.tsv', sep='\\t', index_col=False)\n",
    "    df = df.append(d)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2521, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retailer</th>\n",
       "      <th>sku</th>\n",
       "      <th>title</th>\n",
       "      <th>features_model</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2521</td>\n",
       "      <td>2521</td>\n",
       "      <td>2521</td>\n",
       "      <td>2521</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19</td>\n",
       "      <td>510</td>\n",
       "      <td>371</td>\n",
       "      <td>729</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>mercadolivre</td>\n",
       "      <td>#1035033215</td>\n",
       "      <td>Celular  Samsung Galaxy J7 Prime 2 32gb Preto ...</td>\n",
       "      <td>MS45 3G</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1339</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>1935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            retailer          sku  \\\n",
       "count           2521         2521   \n",
       "unique            19          510   \n",
       "top     mercadolivre  #1035033215   \n",
       "freq            1339            5   \n",
       "\n",
       "                                                    title features_model  \\\n",
       "count                                                2521           2521   \n",
       "unique                                                371            729   \n",
       "top     Celular  Samsung Galaxy J7 Prime 2 32gb Preto ...        MS45 3G   \n",
       "freq                                                   20             27   \n",
       "\n",
       "       correct  \n",
       "count     2521  \n",
       "unique       2  \n",
       "top      False  \n",
       "freq      1935  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('rotuled/0.tsv', sep='\\t', index_col=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df['correct'][df['correct'] == 'T'] = True\n",
    "df['correct'][df['correct'] == 'F'] = False\n",
    "df['correct'][df['correct'] == 't'] = True\n",
    "df['correct'][df['correct'] == 'f'] = False\n",
    "df['correct'][df['correct'] == 'FF'] = False\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1760, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['title', 'features_model'], keep='first').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1766, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['title', 'features_model', 'correct'], keep='first').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retailer</th>\n",
       "      <th>sku</th>\n",
       "      <th>title</th>\n",
       "      <th>features_model</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...</td>\n",
       "      <td>Smartphone Multilaser MS80 32GB 4G Android</td>\n",
       "      <td>MS80 32GB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...</td>\n",
       "      <td>Smartphone Multilaser MS80 32GB 4G Android</td>\n",
       "      <td>MS80 64GB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...</td>\n",
       "      <td>Smartphone Multilaser MS80 32GB 4G Android</td>\n",
       "      <td>MS50 4G</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...</td>\n",
       "      <td>Smartphone Multilaser MS80 32GB 4G Android</td>\n",
       "      <td>MS70 4G</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...</td>\n",
       "      <td>Smartphone Multilaser MS80 32GB 4G Android</td>\n",
       "      <td>MS50R</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  retailer                                                sku  \\\n",
       "0     zoom  0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...   \n",
       "1     zoom  0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...   \n",
       "2     zoom  0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...   \n",
       "3     zoom  0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...   \n",
       "4     zoom  0039a94af8a537fd3c7137dfd7c8cbc8cb419e7dd1f49b...   \n",
       "\n",
       "                                        title features_model correct  \n",
       "0  Smartphone Multilaser MS80 32GB 4G Android      MS80 32GB    True  \n",
       "1  Smartphone Multilaser MS80 32GB 4G Android      MS80 64GB   False  \n",
       "2  Smartphone Multilaser MS80 32GB 4G Android        MS50 4G   False  \n",
       "3  Smartphone Multilaser MS80 32GB 4G Android        MS70 4G   False  \n",
       "4  Smartphone Multilaser MS80 32GB 4G Android          MS50R   False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df.drop_duplicates(subset=['title', 'features_model', 'correct'], keep='first')\n",
    "filtered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for title in np.unique(filtered_df['title']):\n",
    "    space = filtered_df[filtered_df['title'] == title]\n",
    "    models = space['features_model'].values\n",
    "    labels = space['correct'].values\n",
    "    features = extract_features(title, models).T\n",
    "    for x, y in zip(features, labels):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(0.8*len(Y))\n",
    "idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.92      0.90       265\n",
      "        True       0.73      0.61      0.67        88\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       353\n",
      "   macro avg       0.80      0.77      0.78       353\n",
      "weighted avg       0.84      0.85      0.84       353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = int(0.8*len(Y))\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(20), max_iter=2000)\n",
    "clf = clf.fit(X[0:idx,:], Y[0:idx])\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = Y[idx+1:]\n",
    "y_pred = clf.predict(X[idx+1:,:])\n",
    "target_names = ['False', 'True']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1'\n",
    "# scoring = 'accuracy'\n",
    "# scoring = 'precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(20), max_iter=2000)\n",
    "clfs.append(('MLP', clf))\n",
    "scores = cross_val_score(clf, X, Y, cv=10, scoring=scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clfs.append(('RF', clf))\n",
    "scores = cross_val_score(clf, X, Y, cv=10, scoring=scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=2000)\n",
    "clfs.append(('LR', clf))\n",
    "scores = cross_val_score(clf, X, Y, cv=10, scoring=scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clfs.append(('DT', clf))\n",
    "scores = cross_val_score(clf, X, Y, cv=10, scoring=scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "clf = GaussianNB()\n",
    "clfs.append(('NB', clf))\n",
    "scores = cross_val_score(clf, X, Y, cv=10, scoring=scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X, Y, cv=10, scoring=scoring)\n",
    "clfs.append(('ABC', clf))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "scores = cross_val_score(clf, X, Y, cv=10, scoring=scoring)\n",
    "clfs.append(('KNN', clf))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67 (+/- 0.26)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=clfs, voting='soft', weights=np.ones(len(clfs)))\n",
    "scores = cross_val_score(eclf, X, Y, cv=10, scoring=scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
